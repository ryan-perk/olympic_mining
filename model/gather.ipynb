{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# functional libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import math\n",
    "import util\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# model function\n",
    "from processing import extract_parts, draw\n",
    "from model.cmu_model import get_testing_model\n",
    "from config_reader import config_reader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model and movement dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "params, model_params = config_reader()\n",
    "model = get_testing_model()\n",
    "model.load_weights('model/model.h5')\n",
    "\n",
    "# dictionary of possible weightlifting movements and corresponding numerical value\n",
    "movements = {\n",
    "    'snatch_deadlift': 0,\n",
    "    'snatch': 1,\n",
    "    'overhead_squat': 2,\n",
    "    'power_snatch': 3,\n",
    "    'deadlift': 4,\n",
    "    'clean': 5,\n",
    "    'front_squat': 6,\n",
    "    'power_clean': 7\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the peak data (a collection of the 'peaks' or the position of each joint in the frame) of a frame\n",
    "#\n",
    "# |       subject 1 in frame       | subject 2 in frame | ... |\n",
    "# --------------------------------------------------------------\n",
    "# | (x, y, weight, n/total joints) |         ...        | ... |\n",
    "# |             ...                |         ...        | ... |\n",
    "# |                                |                    |     |\n",
    "def get_peaks(video, frame):\n",
    "    return pd.read_pickle('../data/%s_data/%s_peaks' % (video, frame))\n",
    "\n",
    "# returns the subset data (a subset of the provided peaks where the related joints are grouped together)  of a frame\n",
    "#\n",
    "# |       'nose'       | 'neck' | ... |\n",
    "# --------------------------------------\n",
    "# | (n/total joints) |    ...   | ... |\n",
    "# |       ...        |    ...   | ... |\n",
    "# |                  |          |     |\n",
    "def get_sub(video, frame):\n",
    "    return pd.read_pickle('../data/%s_data/%s_subset' % (video, frame))\n",
    "\n",
    "# returns the candidate data (a list of all the coordinates in a frame, in order) of a frame\n",
    "#\n",
    "# |  x  |  y  | weight | (n/total joints) |\n",
    "# ------------------------------------------\n",
    "# | ... | ... |  ...   |       ...        |\n",
    "# |     |     |        |                  |\n",
    "def get_can(video, frame):\n",
    "    return pd.read_pickle('../data/%s_data/%s_candidate' % (video, frame))\n",
    "\n",
    "# returns a list of the frames (formatted as strings - 'frame #') in a given directory\n",
    "def get_frames(path, delim):\n",
    "    frames = os.listdir(path) # add all the frames to a list\n",
    "    frames = list(filter(lambda x: x.split(delim)[0].isdigit(), frames)) # remove none frame files\n",
    "    frames.sort(key = lambda x: int(x.split(delim)[0])) # sort frames in order\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_peaks('clean_1', 4)\n",
    "# get_sub('clean_5', 12)\n",
    "# get_can('clean_8', 61)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. convert a video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a video at 'path' to frame by frame images saved to be edited\n",
    "def video_to_frames(path, div):\n",
    "    # name = path.split('/')[len(path.split('/')) - 1].split('.')[0]\n",
    "    vid = cv2.VideoCapture(path) # load video into a variable\n",
    "    count = 0 # set the frame count\n",
    "    \n",
    "    while(count < vid.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        ret, frame = vid.read() # frame-by-frame\n",
    "        \n",
    "        if count % div != 0:\n",
    "            count += 1\n",
    "            continue\n",
    "        \n",
    "        if np.all(frame != None):\n",
    "            # print('saving.. %s to %s' % (file, loc))\n",
    "            frame = cv2.resize(frame, (910, 1184)) #, fx=0.1, fy=0.1)\n",
    "            cv2.imwrite('../images/edit/%d.jpg' % (count / div), frame) # save image from the current frame \n",
    "        # else:\n",
    "            # print('invalid file.. ' ) \n",
    "        \n",
    "        count += 1 # counter\n",
    "\n",
    "    vid.release() # release capture\n",
    "    cv2.destroyAllWindows() # close the video\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = 'snatch_20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_to_frames('../videos/unprocessed/%s.mov' % video, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. rename the files by movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually rename images in training to their specific movements\n",
    "def new_name(path, loc, mvmt, start, end):\n",
    "    count = start\n",
    "    frames = get_frames(path, '.')\n",
    "    \n",
    "    if mvmt == 0:\n",
    "        while count < len(frames):\n",
    "            os.rename('%s%s' % (path, frames[count]), \n",
    "                      '%s%s.jpg' % (loc, count)) # saves file as frame_movement.jpg\n",
    "            count += 1\n",
    "    else:\n",
    "        while count < end:\n",
    "            os.rename('%s%s' % (path, frames[count - start]), \n",
    "                      '%s%s_%d.jpg' % (loc, count, movements[mvmt])) # saves file as frame_movement.jpg\n",
    "            count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_name('../images/edit/', '../images/training/%s/' % video, 'snatch_deadlift', 0, 11)\n",
    "# new_name('../images/edit/', '../images/training/%s/' % video, 'snatch', 11, 22)\n",
    "# new_name('../images/edit/', '../images/training/%s/' % video, 'overhead_squat', 22, 59)\n",
    "# new_name('../images/edit/', '../images/training/%s/' % video, 'power_snatch', 59, 73)\n",
    "# new_name('../images/edit/', '../images/testing/clean_16/', 0, 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. extract joint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads the images in 'path' and extracts the joint peak, subset, and candidate data then saves to the subsequent (already made) file\n",
    "def frames_to_joints(path, delim):\n",
    "    name = path.split('/')[len(path.split('/')) - 2] # extract name\n",
    "    frames = get_frames(path, delim)\n",
    "    \n",
    "    os.mkdir('./output/%s/' % name) # make image output location\n",
    "    os.mkdir('../data/%s_data/' % name) # make data output location \n",
    "    \n",
    "    for i in frames:\n",
    "        img = cv2.imread(path + i) # read image\n",
    "        bgr_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # convert image to B, G, R\n",
    "    \n",
    "        peaks, subset, candidate = extract_parts(bgr_img, params, model, model_params) # extract peaks, subsets, and candidates\n",
    "        joint_img = draw(bgr_img, peaks, subset, candidate)\n",
    "        \n",
    "        cv2.imwrite('./output/%s/' % i, joint_img) # save image\n",
    "        pd.DataFrame(peaks).to_pickle('../data/%s_data/%s_peaks' % (name, i.split('_')[0])) # save peaks\n",
    "        pd.DataFrame(subset).to_pickle('../data/%s_data/%s_subset' % (name, i.split('_')[0])) # save subset\n",
    "        pd.DataFrame(candidate).to_pickle('../data/%s_data/%s_candidate' % (name, i.split('_')[0]))  # save candidate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames_to_joints('../images/training/snatch_15/', '_') - training\n",
    "# frames_to_joints('../images/testing/clean_16/', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. extract the (x, y) of each joint in a frame and append the movement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dataframe with the features as the columns with a target at the end and the (x, y) being the feature data and the movement being the target data\n",
    "def zero_frame_joint_data(name, frame, movement, count):\n",
    "    can = 0 # defaults to 0 since training data should only have one\n",
    "    subset = get_sub(name, frame) # get subset data\n",
    "    candidate = get_can(name, frame) # get candidate data\n",
    "    \n",
    "    if can < len(subset): # len(subset) is equivalent to the number of figures mapped in the frame\n",
    "        xy = []\n",
    "        subset = subset.loc[can, :(len(subset.loc[0, :]) - 3)].astype(int) # array of all the coordinates pertaining to the candidate \n",
    "            \n",
    "        for j in subset:\n",
    "            try:\n",
    "                x = int(candidate.loc[j:j, :0][0]) / 256\n",
    "                y = int(candidate.loc[j:j, 1:1][1]) / 256\n",
    "            except:\n",
    "                try:\n",
    "                    x = df.loc[count - 1:count - 1, count:count].values[0][0][0] / 256 \n",
    "                    y = df.loc[count - 1:count - 1, count:count].values[0][0][1] / 256 \n",
    "                except: \n",
    "                    x = None\n",
    "                    y = None\n",
    "            xy.append((x, y)) # append (x, y) of each joint\n",
    "            \n",
    "        # grip and elbow width\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[4][0] - xy[7][0])**2 + (xy[7][1] - xy[7][1])**2)) # Rwri_Lwri\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[3][0] - xy[6][0])**2 + (xy[3][1] - xy[6][1])**2)) # Relb_Lelb\n",
    "        except:\n",
    "            xy.append(None)\n",
    "            \n",
    "        # arm measurements \n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[4][0] - xy[3][0])**2 + (xy[4][1] - xy[3][1])**2)) # Rwri_Relb\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[4][0] - xy[2][0])**2 + (xy[4][1] - xy[2][1])**2)) # Rwri_Rsho\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[3][0] - xy[2][0])**2 + (xy[3][1] - xy[2][1])**2)) # Relb_Rsho\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[7][0] - xy[6][0])**2 + (xy[7][1] - xy[6][1])**2)) # Lwri_Lelb\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[7][0] - xy[5][0])**2 + (xy[7][1] - xy[5][1])**2)) # Lwri_Lsho\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[6][0] - xy[5][0])**2 + (xy[6][1] - xy[5][1])**2)) # Lelb_Lsho\n",
    "        except:\n",
    "            xy.append(None)\n",
    "            \n",
    "        # leg measurements\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[10][0] - xy[9][0])**2 + (xy[10][1] - xy[9][1])**2)) # Rank_Rkne\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[10][0] - xy[8][0])**2 + (xy[10][1] - xy[8][1])**2)) # Rank_Rhip\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[9][0] - xy[8][0])**2 + (xy[9][1] - xy[8][1])**2)) # Rkne_Rhip\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[13][0] - xy[12][0])**2 + (xy[13][1] - xy[12][1])**2)) # Lank_Lkne\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[13][0] - xy[11][0])**2 + (xy[13][1] - xy[11][1])**2)) # Lank_Lhip\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[12][0] - xy[11][0])**2 + (xy[12][1] - xy[11][1])**2)) # Lkne_Lhip\n",
    "        except:\n",
    "            xy.append(None)\n",
    "            \n",
    "        # wrist to leg measurements     \n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[4][0] - xy[8][0])**2 + (xy[4][1] - xy[8][1])**2)) # Rwri_Rhip\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[4][0] - xy[9][0])**2 + (xy[4][1] - xy[9][1])**2)) # Rwri_Rkne\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[4][0] - xy[10][0])**2 + (xy[4][1] - xy[10][1])**2)) # Rwri_Rank\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[7][0] - xy[11][0])**2 + (xy[7][1] - xy[11][1])**2)) # Lwri_Lhip\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[7][0] - xy[12][0])**2 + (xy[7][1] - xy[12][1])**2)) # Lwri_Lkne\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[7][0] - xy[13][0])**2 + (xy[7][1] - xy[13][1])**2)) # Lwri_Lank\n",
    "        except:\n",
    "            xy.append(None)\n",
    "            \n",
    "            \n",
    "        # elbow to leg measurements    \n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[3][0] - xy[9][0])**2 + (xy[3][1] - xy[9][1])**2)) # Relb_Rkne\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[3][0] - xy[10][0])**2 + (xy[3][1] - xy[10][1])**2)) # Relb_Rank\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[6][0] - xy[12][0])**2 + (xy[6][1] - xy[12][1])**2)) # Lelb_Lkne\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[6][0] - xy[13][0])**2 + (xy[6][1] - xy[13][1])**2)) # Lelb_Lank\n",
    "        except:\n",
    "            xy.append(None)\n",
    "\n",
    "        # height measurements\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[10][0])**2 + (xy[0][1] - xy[10][1])**2)) # nose_Rank\n",
    "        except:\n",
    "            xy.append(None) \n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[13][0])**2 + (xy[0][1] - xy[13][1])**2)) # nose_Lank\n",
    "        except:\n",
    "            xy.append(None) \n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[9][0])**2 + (xy[0][1] - xy[9][1])**2)) # nose_Rkne\n",
    "        except:\n",
    "            xy.append(None) \n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[12][0])**2 + (xy[0][1] - xy[12][1])**2)) # nose_Lkne\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[8][0])**2 + (xy[0][1] - xy[8][1])**2)) # nose_Rhip\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[11][0])**2 + (xy[0][1] - xy[11][1])**2)) # nose_Lhip\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[4][0])**2 + (xy[0][1] - xy[4][1])**2)) # nose_Rwri\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[7][0])**2 + (xy[0][1] - xy[7][1])**2)) # nose_Lwri\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[3][0])**2 + (xy[0][1] - xy[3][1])**2)) # nose_Relb\n",
    "        except:\n",
    "            xy.append(None)\n",
    "        try:\n",
    "            xy.append(math.sqrt((xy[0][0] - xy[6][0])**2 + (xy[0][1] - xy[6][1])**2)) # nose_Lelb\n",
    "        except:\n",
    "            xy.append(None)\n",
    "            \n",
    "        xy.append(movement) # append the movement \n",
    "        \n",
    "        return pd.DataFrame(np.array(xy)).T # convert to passable dataframe\n",
    "    else:\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = 'pwrsnatch_8'\n",
    "\n",
    "# frames = get_frames('../images/training/%s/' % video, '_')\n",
    "# df = pd.DataFrame() # video joint data\n",
    "# count = 0\n",
    "# div = 1\n",
    "\n",
    "# for i in frames:\n",
    "    # if count % div != 0:\n",
    "        # count += 1\n",
    "        # continue\n",
    "    \n",
    "    # frame = i.split('_')[0]\n",
    "    # movement = i.split('_')[1].split('.')[0]\n",
    "\n",
    "    # df = df.append(zero_frame_joint_data('%s' % video, frame, movement, count / div), ignore_index = True)\n",
    "    # count += 1\n",
    "    \n",
    "# df.to_csv('../data/2d/%s_2d_data.csv' % video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = 'test_2'\n",
    "\n",
    "# frames = get_frames('../images/testing/%s/' % video, '.')\n",
    "# df = pd.DataFrame() # video joint data\n",
    "# count = 0\n",
    "# div = 1\n",
    "\n",
    "# for i in frames:\n",
    "    # if count % div != 0:\n",
    "        # count += 1\n",
    "        # continue\n",
    "        \n",
    "    # df = df.append(zero_frame_joint_data('%s' % video, i, 100, count / div), ignore_index = True)\n",
    "    # count += 1\n",
    "\n",
    "# df.to_csv('../data/2d/%s_2d_data.csv' % video)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. convert the 2D data to data over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_data(data):\n",
    "    new = []\n",
    "    count = 0\n",
    "    \n",
    "    while count < len(data) - 1:\n",
    "        temp = []\n",
    "        cur = data.values.tolist()[count] # values for the current frame\n",
    "        nxt = data.values.tolist()[count + 1] # values for the proceeding frame \n",
    "        \n",
    "        for i in range(len(cur)):\n",
    "            if i < 18: # first 18 are joint coordinates \n",
    "                try:\n",
    "                    temp.append((nxt[i][1] - cur[i][1]) / (nxt[i][0] - cur[i][0])) # append slope\n",
    "                except:\n",
    "                    temp.append(0) # slope may be 0\n",
    "            elif i < len(cur) - 1:\n",
    "                try:\n",
    "                    temp.append((nxt[i] + cur[i]) / 2) # appends the avg distance between the two frames\n",
    "                    temp.append(nxt[i] - cur[i]) # appends the change in distance between the two frames\n",
    "                except:\n",
    "                    temp.append(None)\n",
    "                    temp.append(None)\n",
    "            else:\n",
    "                temp.append(cur[i]) # append movement\n",
    "        \n",
    "        new.append(temp) # append data and move to next frame\n",
    "        count += 1\n",
    "    \n",
    "    return pd.DataFrame(new)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_data(df).fillna(0).to_csv('../data/time/%s_time_data.csv' % video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_train_data(video):\n",
    "    tic = time.time()\n",
    "    # frames_to_joints('../images/training/%s/' % video, '_') # exrtract joint data - uncomment to run through model\n",
    "    frames = get_frames('../images/training/%s/' % video, '_')\n",
    "    video_joint_data = pd.DataFrame() # video joint data\n",
    "    count = 0\n",
    "\n",
    "    for i in frames:\n",
    "        frame = i.split('_')[0]\n",
    "        movement = i.split('_')[1].split('.')[0]\n",
    "        video_joint_data = video_joint_data.append(zero_frame_joint_data(video, frame, movement, count), ignore_index = True) # add joint coordinate and distance data to the video array\n",
    "        count += 1\n",
    "    \n",
    "    time_data(video_joint_data).to_csv('./output/data/%s_time_data' % video) # calculate and save the features over the course of the video\n",
    "    toc = time.time()\n",
    "    print('time: %.2f' % (toc - tic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather_train_data('snatch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_test_data(video, fps_factor):\n",
    "    tic = time.time()\n",
    "    #video_to_frames('../videos/unprocessed/%s.mov' % video, fps_factor)\n",
    "    #new_name('../images/edit/', '../images/testing/%s/' % video, 0, 0, 100)\n",
    "    #frames_to_joints('../images/testing/%s/' % video, '.') # exrtract joint data - uncomment to run through model\n",
    "    frames = get_frames('../images/testing/%s/' % video, '.')\n",
    "    video_joint_data = pd.DataFrame() # video joint data\n",
    "    count = 0\n",
    "\n",
    "    for i in frames:\n",
    "        video_joint_data = video_joint_data.append(zero_frame_joint_data(video, i, 100, count), ignore_index = True) # add joint coordinate and distance data to the video array\n",
    "        count += 1\n",
    "    \n",
    "    time_data(video_joint_data).to_csv('../data/time/%s_time_data.csv' % video) # calculate and save the features over the course of the video\n",
    "    toc = time.time()\n",
    "    print('time: %.2f' % (toc - tic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather_test_data('test_2', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('./zzz.jpg') # read image\n",
    "# foo = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # convert image to B, G, R\n",
    "# foo = cv2.resize(foo, (128, 128))#, fx=0.1, fy=0.1)\n",
    "# plt.imshow(foo)\n",
    "\n",
    "# tic = time.time()\n",
    "# peaks, subset, candidate = extract_parts(foo, params, model, model_params)\n",
    "# joint_img = draw(foo, peaks, subset, candidate)  \n",
    "# toc = time.time()\n",
    "# print('time: %.2f' % (toc - tic))\n",
    "    \n",
    "# plt.imshow(joint_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
